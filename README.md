

## About ME

- I'm Zhang-Each
  - A graduate student in Zhejiang University, major in Computer Science
  - Study Knowledge Graphs(KG) and Natural Language Processing(NLP) in ZJU-KG lab.
- Learning open courses released by Stanford/MIT/CMU
- Blog: [link here](https://zhang-each.github.io/)
- Notebook: [link here](https://zhang-each.github.io/My-CS-Notebook/)
- Personal Page: [link here](https://zhang-each.github.io/CV/)


## Publication
- Knowledge Graph Completion with Pre-trained Multimodal Transformer and Twins Negative Sampling. (First Author, Accepted by [KDD-2022 Undergraduate consortium](https://kdd.org/kdd2022/), [ArXiv](https://arxiv.org/abs/2209.07084))
- Tele-Knowledge Pre-training for Fault Analysis. (Accepted by ICDE-2023 Industry Track, [ArXiv](https://arxiv.org/abs/2210.11298))
- Modality-Aware Negative Sampling for Multi-modal Knowledge Graph Embedding. (Accepted by IJCNN 2023, [ArXiv](https://arxiv.org/abs/2304.11618))
- CausE: Towards Causal Knowledge Graph Embedding. (Accepted by CCKS 2023, [ArXiv](https://arxiv.org/abs/2307.11610))
- MACO: A Modality Adversarial and Contrastive Framework for Modality-missing Multi-modal Knowledge Graph Completion. (Accepted by NLPCC 2023, [ArXiv](https://arxiv.org/abs/2308.06696))
- Unleashing the Power of Imbalanced Modality Information for Multi-modal Knowledge Graph Completion. (Accepted by COLING 2024, [ArXiV](https://arxiv.org/pdf/2402.15444))
- NativE: Multi-modal Knowledge Graph Completion in the Wild. (Accepted by SIGIR 2024, [ArXiV](https://www.researchgate.net/publication/379508830_NativE_Multi-modal_Knowledge_Graph_Completion_in_the_Wild)).
- Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering. (Accepted by ACL 2024 Findings, [ArXiv](https://arxiv.org/abs/2311.06503))

## Preprint
- Making Large Language Models Perform Better in Knowledge Graph Completion. ([ArXiv](https://arxiv.org/abs/2310.07579))
- Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey. ([ArXiv](https://arxiv.org/pdf/2402.05391))
- MyGO: Discrete Modality Information as Fine-Grained Tokens for Multi-modal Knowledge Graph Completion. ([ArXiv](https://arxiv.org/abs/2404.09468))
- Multi-domain Knowledge Graph Collaborative Pre-training and Prompt Tuning for Diverse Downstream Tasks. ([ArXiV](https://arxiv.org/abs/2405.13085))
- Mixture of Modality Knowledge Experts for Robust Multi-modal Knowledge Graph Completion. ([ArXiV](https://arxiv.org/abs/2405.16869))

## Stats

<a href="https://github.com/zhang-each/zhang-each">
  <img align="center" src="https://github-readme-stats.vercel.app/api/top-langs/?username=zhang-each&langs_count=5&layout=compact&exclude_repo=Zhang-Each.github.io,g22_learning_in_zju" alt="Zhang-Each's GitHub Stats" /></a>

<a href="https://github.com/zhang-each">
  <img align="center" src="https://github-readme-stats.vercel.app/api?username=zhang-each&show_icons=true&line_height=27&count_private=true&title_color=6aa6f8" alt="Haofei Yu's GitHub Stats" /></a>

![nothing](https://visitor-badge.laobi.icu/badge?page_id=zhang-each)
